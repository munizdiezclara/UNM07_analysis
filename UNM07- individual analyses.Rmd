---
title: "UNM07 (individual analyses)"
output:
  pdf_document: default
date: "2023-09-14"
---

```{r setup, include=FALSE}
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library("writexl")
load("C:/Users/munizdie/OneDrive - Lancaster University/Experiments/Recognition Memory/UNM07/UNM07_analysis/UNM07_proc_data.RData")
# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}

# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = TRUE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}

```

# Design

In this experiment, the differences in recognition memory of predictive and non-predictive cues was examined under both a certain and an uncertain training. Both groups received a training in which two cues are presented in each trial followed by an outcome. Only one of the cues is predictive of the outcome, whereas the other appears the same amount of times with each of the two possible outcomes. In one of this groups, the contingency between the predictive cues and their respective outcomes is of 1, so in each trial that the predictive cue is presented its corresponding outcome follows. For the other group, this contingency is of 0.8, so the predictive cue is followed by the outcome on 80% of the trials. After the training phase, all subjects were presented two cues on each trial, one that was presented on training and one that wasn't, but that was similar to the other cues presented on the training phase (a pair of balls swapped colours in the fouls). Subjects had to choose which one they had seen before and rate how confident they were of their choice.

+------------+---------------------------+------------+
| Group      | Training                  | Test2      |
+============+:=========================:+:==========:+
| Certain    | AX - O1                   | A vs *b*   |
|            |                           |            |
|            |                           | A vs *x*   |
|            |                           |            |
|            |                           | A vs *y*   |
+------------+---------------------------+------------+
|            | AY - O1                   | B vs *a*   |
|            |                           |            |
|            |                           | B vs *x*   |
|            |                           |            |
|            |                           | B vs *y*   |
+------------+---------------------------+------------+
|            | BX - 02                   | X vs *a*   |
|            |                           |            |
|            |                           | X vs *b*   |
|            |                           |            |
|            |                           | X vs *y*   |
+------------+---------------------------+------------+
|            | BY - O2                   | Y vs *a*   |
|            |                           |            |
|            |                           | Y vs *b*   |
|            |                           |            |
|            |                           | Y vs *x*   |
+------------+---------------------------+------------+
| Uncertain  | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*   |
|            |                           |            |
|            |                           | A vs *x*   |
|            |                           |            |
|            |                           | A vs *y*   |
+------------+---------------------------+------------+
|            | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*   |
|            |                           |            |
|            |                           | B vs *x*   |
|            |                           |            |
|            |                           | B vs *y*   |
+------------+---------------------------+------------+
|            | 0.8 BX - O1 / 0.2 BX - O2 | X vs *a*   |
|            |                           |            |
|            |                           | X vs *b*   |
|            |                           |            |
|            |                           | X vs *y*   |
+------------+---------------------------+------------+
|            | 0.8 BY - O1 / 0.2 BY - O2 | Y vs *a*   |
|            |                           |            |
|            |                           | Y vs *b*   |
|            |                           |            |
|            |                           | Y vs *x*   |
+------------+---------------------------+------------+

# Results
## Training
Let's take a look on how accuracy is distributed on the sample.
```{r, include=FALSE}
#Create probable response variable, as we are using the uncertain condition
training <- training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))
```
```{r, include=FALSE}
resp <- training %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))

#range of responding
range(resp$mean_response) # 0.2105263 1.0000000
#range of responding in certain
certain_resp <- filter(resp, condition == "Certain")
range(certain_resp$mean_response) # 0.3 1.0000000
#range of responding in uncertain
uncertain_resp <- filter(resp, condition == "Uncertain")
range(uncertain_resp$mean_response) # 0.2105263 1.0000000

#subjects that respond over 0.6
accurate_resp <- filter(resp, block == 8 & mean_response >= 0.6)
accurate_responders <- accurate_resp$pNum
```

46 subjects had a mean accuracy over 0.6 in the last block of the experiment, 26 in the certain condition and 20 in the uncertain condition. Let's repeat the analysis jus with this subjects


## Test
### Accuracy
```{r, include = FALSE}
MA_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by(cue_type, condition) %>%
  summarise(mean_acc = mean(acc, na.rm = TRUE),
            sd_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```
```{r, echo = FALSE}
ggplot(MA_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_acc, fill = condition)) +
  geom_errorbar(aes(x= cue_type, y = mean_acc, ymin = mean_acc-sd_acc, ymax = mean_acc+sd_acc), color = "black", width=.1,position=position_dodge(0.05)) +
  labs(title = "Mean accuracy in the test phase")
```
```{r, include=FALSE}
#ANOVA
acc_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mean_acc = mean(acc, na.rm = TRUE))
acc_test$pNum <- factor(acc_test$pNum)
acc_test$condition <- factor(acc_test$condition)
acc_test$predictiveness <- factor(acc_test$predictiveness)
ANOVA_acc_test <- aov_car(formula = mean_acc ~ condition + Error(pNum/predictiveness), data = acc_test)
print(ANOVA_acc_test)

bay_ANOVA_acc_test <- anovaBF(formula = mean_acc ~ condition + predictiveness + pNum,
        data = data.frame(acc_test),
        whichRandom = "pNum")
print(bay_ANOVA_acc_test)
bay_ANOVA_acc_test_int <- bay_ANOVA_acc_test[4]/bay_ANOVA_acc_test[3]
print(bay_ANOVA_acc_test_int)
```

```{r, include = FALSE}
# Pairwise comparisons between group levels
#interaction analysis
acc_test_interaction <- emmeans(ANOVA_acc_test, ~ predictiveness|condition)
pairs(acc_test_interaction, adjust = "bon")
```

There are no differences in accuracy due to the condition or the predictiveness, and the bayesian analysis indicates moderate evidence for the null hypothesis in the fromer and anecdtoal in the latter, except for the interaction, where we observe anecdotal evidence for the alternative hypothesis (respectively, `r apa(ANOVA_acc_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_test[1])`; `r apa(ANOVA_acc_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_test[2])`). However, the interaction is significant and the bayesian evidence is moderate (`r apa(ANOVA_acc_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_test_int[1])`). Bonferroni corrected pairwise comparisons indicated that there the accuracy was higher for the predictive cues in the certain condition (*T*(58) = -0.144, *p* = 0.009) but there were no differences in the uncertain condition (*T*(58) = 0.067, *p* = 0.272).

### Memory score
```{r, include = FALSE}
MM_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by(cue_type, condition) %>%
  summarise(mean_mem = mean(mem_score, na.rm = TRUE),
            sd_mem = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))
```
```{r, echo = FALSE}
ggplot(MM_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem, fill = condition)) +
  geom_errorbar(aes(x= cue_type, y = mean_mem, ymin = mean_mem-sd_mem, ymax = mean_mem+sd_mem), color = "black", width=.1,position=position_dodge(0.05)) +
  labs(title = "Mean memory score in the test phase")
```
```{r, include=FALSE}
#ANOVA
mem_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mean_mem = mean(mem_score, na.rm = TRUE))
mem_test$pNum <- factor(mem_test$pNum)
mem_test$condition <- factor(mem_test$condition)
mem_test$predictiveness <- factor(mem_test$predictiveness)
ANOVA_mem_test <- aov_car(formula = mean_mem ~ condition + Error(pNum/predictiveness), data = mem_test)
print(ANOVA_mem_test)

bay_ANOVA_mem_test <- anovaBF(formula = mean_mem ~ condition + predictiveness + pNum,
        data = data.frame(mem_test),
        whichRandom = "pNum")
print(bay_ANOVA_mem_test)
bay_ANOVA_mem_test_int <- bay_ANOVA_mem_test[4]/bay_ANOVA_mem_test[3]
print(bay_ANOVA_mem_test_int)
```
```{r, include = FALSE}
# Pairwise comparisons between group levels
#interaction analysis
mem_test_interaction <- emmeans(ANOVA_mem_test, ~ predictiveness|condition)
pairs(mem_test_interaction, adjust = "bon")
```
There are no significant differences in memory due to the condition or the predictiveness, and the bayesian analysis indicates anecdotal evidence for the null hypothesis in all cases (respectively, `r apa(ANOVA_mem_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_mem_test[1])`; `r apa(ANOVA_mem_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_mem_test[2])`). However, the interaction is significant and the bayesian evidence is moderate (`r apa(ANOVA_acc_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_test_int[1])`). Bonferroni corrected pairwise comparisons indicated that there the accuracy was higher for the predictive cues in the certain condition (*T*(58) = -2.2, *p* = 0.006) but there were no differences in the uncertain condition (*T*(58) = 0.633, *p* = 0.467).

### Corrected memory score (with errors out)
```{r, include = FALSE}
c_test <- filter(test, acc == 1)
MCMS_test <- filter(c_test, pNum %in% accurate_responders) %>%
  group_by(cue_type, condition) %>%
  summarise(mean_mem = mean(mem_score, na.rm = TRUE),
            sd_mem = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))
```
```{r, echo = FALSE}
ggplot(MCMS_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem, fill = condition)) +
  geom_errorbar(aes(x= cue_type, y = mean_mem, ymin = mean_mem-sd_mem, ymax = mean_mem+sd_mem), color = "black", width=.1,position=position_dodge(0.05)) +
  labs(title = "Mean corrected memory score in the test phase")
```
```{r, include=FALSE}
#ANOVA
cms_test <- filter(c_test, pNum %in% accurate_responders) %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mean_mem = mean(mem_score, na.rm = TRUE))
cms_test$pNum <- factor(cms_test$pNum)
cms_test$condition <- factor(cms_test$condition)
cms_test$predictiveness <- factor(cms_test$predictiveness)
ANOVA_cms_test <- aov_car(formula = mean_mem ~ condition + Error(pNum/predictiveness), data = cms_test)
print(ANOVA_cms_test)

bay_ANOVA_cms_test <- anovaBF(formula = mean_mem ~ condition + predictiveness + pNum,
        data = data.frame(cms_test),
        whichRandom = "pNum")
print(bay_ANOVA_cms_test)
bay_ANOVA_cms_test_int <- bay_ANOVA_cms_test[4]/bay_ANOVA_cms_test[3]
print(bay_ANOVA_cms_test_int)
```
There are no significant differences in memory due to the condition, the predictiveness or the interaction of them, and the bayesian analysis indicates anecdotal evidence for the alterantive hypothesis for the effect of certainty, moderate null for predictiveness and anecdotal null for the interaction (respectively, `r apa(ANOVA_cms_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_cms_test[1])`; `r apa(ANOVA_cms_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_cms_test[2])`; `r apa(ANOVA_cms_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_cms_test_int[1])`).

### Other corrected memory score
```{r, include = FALSE}
Mc_mem_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by(cue_type, condition) %>%
  summarise(mean_c_mem = mean(c_mem_score, na.rm = TRUE),
            sd_c_mem = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```
```{r, echo = FALSE}
ggplot(Mc_mem_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_c_mem, fill = condition)) +
  geom_errorbar(aes(x= cue_type, y = mean_c_mem, ymin = mean_c_mem-sd_c_mem, ymax = mean_c_mem+sd_c_mem), color = "black", width=.1,position=position_dodge(0.05)) +
  labs(title = "Mean corrected memory score in the test phase")
```
```{r, include=FALSE}
#ANOVA
c_mem_test <- filter(test, pNum %in% accurate_responders) %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mean_c_mem = mean(c_mem_score, na.rm = TRUE))
c_mem_test$pNum <- factor(c_mem_test$pNum)
c_mem_test$condition <- factor(c_mem_test$condition)
c_mem_test$predictiveness <- factor(c_mem_test$predictiveness)
ANOVA_c_mem_test <- aov_car(formula = mean_c_mem ~ condition + Error(pNum/predictiveness), data = c_mem_test)
print(ANOVA_c_mem_test)

bay_ANOVA_c_mem_test <- anovaBF(formula = mean_c_mem ~ condition + predictiveness + pNum,
        data = data.frame(c_mem_test),
        whichRandom = "pNum")
print(bay_ANOVA_c_mem_test)
bay_ANOVA_c_mem_test_int <- bay_ANOVA_c_mem_test[4]/bay_ANOVA_c_mem_test[3]
print(bay_ANOVA_c_mem_test_int)
```
```{r, include = FALSE}
# Pairwise comparisons between group levels
#interaction analysis
c_mem_test_interaction <- emmeans(ANOVA_c_mem_test, ~ predictiveness|condition)
pairs(c_mem_test_interaction, adjust = "bon")
```

There are no significant differences in memory due to the condition or the predictiveness, and the bayesian analysis indicates anecdotal evidence for the null hypothesis for certainty and predictiveness (respectively, `r apa(ANOVA_c_mem_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_c_mem_test[1])`; `r apa(ANOVA_c_mem_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_c_mem_test[2])`). However, the interaction was found significant and the bayesian evidence moderate (`r apa(ANOVA_c_mem_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_c_mem_test_int[1])`). Bonferroni corrected pairwise comparisons indicated that there the accuracy was higher for the predictive cues in the certain condition (*T*(58) = -1.397, *p* = 0.006) but there were no differences in the uncertain condition (*T*(58) = 0.429, *p* = 0.44).

## Differences in uncertain between high and low accuracy
```{r, include = FALSE}
high <- filter(resp, condition == "Uncertain" & block == 8 & mean_response >= 0.6)
high_responders <- high$pNum
low <- filter(resp, condition == "Uncertain" & block == 8 & mean_response < 0.6)
low_responders <- low$pNum
test <- test %>%
  mutate(responder = case_when(pNum %in% high ~ "high",
                               pNum %in% low ~ "low"))
```
